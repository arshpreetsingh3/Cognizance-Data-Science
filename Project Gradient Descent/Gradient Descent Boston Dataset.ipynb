{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.loadtxt(\"0000000000002417_training_boston_x_y_train.csv\", delimiter=\",\")\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=train_data[:,0:13]\n",
    "train_y=train_data[:,13:14]\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "(379, 14)\n"
     ]
    }
   ],
   "source": [
    "    print(len(train_x))\n",
    "    ap=np.array([1 for i in range(len(train_x))])\n",
    "    ap=ap.reshape(379,1)\n",
    "    train_x= np.append(train_x,ap,axis=1)\n",
    "    print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(result,m,train):\n",
    "    c=0\n",
    "    for i in range(len(train)):\n",
    "        c+= (result[i][0]-(m*train[i]).sum())**2\n",
    "    return c/len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent1(m,train,result,alpha,itr):\n",
    "    slope=np.array([0 for i in range(len(train_x[0]))])\n",
    "    for i in range(itr):\n",
    "        for q in range(len(m)):\n",
    "            slp=0\n",
    "            for j in range(len(train)):\n",
    "                slp+=(-2/len(train))*(result[j][0]-(m*train[j]).sum())*(train[j][q])\n",
    "            slope[q]=slp\n",
    "        m=m-alpha*slope\n",
    "        print(\"cost\",i+1,\":\",cost(result,m,train),\"    \",m)\n",
    "    print(m)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent2(m,train,result,alpha,itr):\n",
    "    slope=np.array([0 for i in range(len(train_x[0]))])\n",
    "    for i in range(itr):\n",
    "        for j in range(len(train)):\n",
    "            slp=0\n",
    "            for q in range(len(m)):\n",
    "                slp+=(-2/len(train))*(result[j][0]-(m*train[j]).sum())*(train[j][q])\n",
    "            slope[q]=slp\n",
    "        m=m-alpha*slope\n",
    "        print(\"cost\",i+1,\":\",cost(result,m,train),\"    \",m)\n",
    "    print(m)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent():\n",
    "    alpha=0.1\n",
    "    itr=100\n",
    "    m=np.array([0 for i in range(len(train_x[0]))])\n",
    "    print(m)\n",
    "    m=descent1(m,train_x,train_y,alpha,itr)\n",
    "    print(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    return gradientDescent()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(train,m):\n",
    "    result=np.array([0 for i in range(len(train))]).reshape(len(train),1)\n",
    "    for i in range(len(train)):\n",
    "        result[i]=(train[i]*m).sum()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_truth,y_pred):\n",
    "    u=((y_truth-y_pred)**2).sum()\n",
    "    v=((y_truth-y_truth.mean())**2).sum()\n",
    "    return 1-u/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    m=fit()\n",
    "    result=prediction(train_x,m)\n",
    "    print(score(train_y,result))\n",
    "    finalResult=prediction(test_x,m)\n",
    "    print(finalResult.shape)\n",
    "    np.savetxt(\"prediction_boston.csv\", finalResult, delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.loadtxt('0000000000002417_test_boston_x_test.csv',delimiter=',')\n",
    "test_data.shape\n",
    "test_x=test_data\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 14)\n"
     ]
    }
   ],
   "source": [
    "    ap=np.array([1 for i in range(len(test_x))])\n",
    "    ap=ap.reshape(len(test_x),1)\n",
    "    test_x= np.append(test_x,ap,axis=1)\n",
    "    print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "cost 1 : 374.31792864598566      [-0.6  0.6 -0.7  0.4 -0.6  1.4 -0.4  0.4 -0.4 -0.6 -0.8  0.5 -1.3  4.5]\n",
      "cost 2 : 248.0189124400572      [-0.6  0.5 -0.6  0.7 -0.4  2.  -0.2  0.1 -0.1 -0.4 -0.9  0.5 -1.6  8.1]\n",
      "cost 3 : 167.5280256937172      [-6.00000000e-01  5.00000000e-01 -6.00000000e-01  9.00000000e-01\n",
      " -4.00000000e-01  2.50000000e+00 -1.00000000e-01 -1.00000000e-01\n",
      "  2.77555756e-17 -4.00000000e-01 -1.10000000e+00  5.00000000e-01\n",
      " -1.90000000e+00  1.10000000e+01]\n",
      "cost 4 : 117.03960527234365      [-0.6  0.5 -0.6  1.  -0.4  2.8  0.  -0.3  0.1 -0.4 -1.2  0.5 -2.1 13.3]\n",
      "cost 5 : 85.44979621890725      [-0.6  0.5 -0.6  1.  -0.4  3.   0.  -0.4  0.2 -0.4 -1.3  0.5 -2.3 15.1]\n",
      "cost 6 : 64.35032373751123      [-0.6  0.5 -0.6  1.  -0.4  3.1  0.  -0.5  0.3 -0.4 -1.3  0.5 -2.5 16.6]\n",
      "cost 7 : 50.92041334589953      [-0.6  0.5 -0.6  1.  -0.4  3.2  0.  -0.6  0.3 -0.4 -1.3  0.5 -2.6 17.8]\n",
      "cost 8 : 42.68812248922364      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -0.7  0.3 -0.4 -1.3  0.5 -2.7 18.7]\n",
      "cost 9 : 37.42709356405509      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -0.8  0.3 -0.4 -1.3  0.5 -2.8 19.4]\n",
      "cost 10 : 33.67410103599529      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -0.9  0.3 -0.4 -1.3  0.5 -2.9 20. ]\n",
      "cost 11 : 31.070172698659583      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.   0.3 -0.4 -1.3  0.5 -3.  20.5]\n",
      "cost 12 : 29.316336345663213      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.1  0.3 -0.4 -1.3  0.5 -3.1 20.9]\n",
      "cost 13 : 28.173619770621496      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 21.2]\n",
      "cost 14 : 27.648488239683246      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 21.4]\n",
      "cost 15 : 27.203356708744963      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 21.6]\n",
      "cost 16 : 26.838225177806727      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 21.8]\n",
      "cost 17 : 26.68565941233759      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 21.9]\n",
      "cost 18 : 26.553093646868444      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.2 22. ]\n",
      "cost 19 : 26.350146336056724      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.2  0.3 -0.4 -1.3  0.5 -3.3 22.1]\n",
      "cost 20 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 21 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 22 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 23 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 24 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 25 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 26 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 27 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 28 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 29 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 30 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 31 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 32 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 33 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 34 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 35 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 36 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 37 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 38 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 39 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 40 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 41 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 42 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 43 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 44 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 45 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 46 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 47 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 48 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 49 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 50 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 51 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 52 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 53 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 54 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 55 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 56 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 57 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 58 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 59 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 60 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 61 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 62 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 63 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 64 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 65 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 66 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 67 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 68 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 69 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 70 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 71 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 72 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 73 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 74 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 75 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 76 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 77 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 78 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 79 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 80 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 81 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 82 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 83 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 84 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 85 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 86 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 87 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 88 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 89 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 90 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 91 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 92 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 93 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 94 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 95 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 96 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 97 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 98 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 99 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "cost 100 : 26.159783860422568      [-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "[-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "[-0.6  0.5 -0.6  1.  -0.4  3.3  0.  -1.3  0.3 -0.4 -1.3  0.5 -3.3 22.2]\n",
      "0.6977802602463332\n",
      "(127, 1)\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
