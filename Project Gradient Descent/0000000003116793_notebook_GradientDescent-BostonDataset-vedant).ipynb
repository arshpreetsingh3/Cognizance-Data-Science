{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y, x, m_c_arr):\n",
    "    ans = 0\n",
    "    #numFeatures = len(m_c_arr)\n",
    "    numRows = len(x)\n",
    "    for i in range(numRows):\n",
    "        ans += (y[i] - (m_c_arr * x[i]).sum()) ** 2\n",
    "    return ans/numRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepGradient(m_c_arr, x, y, lr):\n",
    "    m_c_slopeSum = m_c_arr * 0.0\n",
    "    numFeatures = len(m_c_arr)\n",
    "    numRows = len(x)\n",
    "    for i in range(numRows):\n",
    "        #m_c_slopeSum = m_c_arr * 0.0\n",
    "        smallAns = ( y[i] - (m_c_arr * x[i]).sum() )\n",
    "        for featureNo in range(numFeatures):\n",
    "            m_c_slopeSum[featureNo] += smallAns  * x[i][featureNo] * (-2/numRows)\n",
    "        m_c_arr = m_c_arr - m_c_slopeSum * lr    \n",
    "    return m_c_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(data, numIter, lr):\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df[14] = df[13]\n",
    "    df[13] = 1\n",
    "    N = len(df.values[0])\n",
    "    y = df[14]   \n",
    "    del df[14]\n",
    "    for i in range(14, 20):\n",
    "        df[i] = df[i-14] * df[i-13]\n",
    "    x = df.values\n",
    "    print(x)\n",
    "    m_c_arr = (df.values)[0] * 0\n",
    "    numRows = len(x)\n",
    "    numFeatures = len(m_c_arr)\n",
    "    \n",
    "    \n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "    scaler.fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    print(x.shape)\n",
    "    print(x.std(axis = 0))\n",
    "    \n",
    "    for i in range(numIter):\n",
    "        m_c_arr = stepGradient(m_c_arr, x, y, lr)\n",
    "        print(i, \" Cost: \", cost(y, x, m_c_arr))\n",
    "    return m_c_arr, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data):\n",
    "    numIter = 150\n",
    "    lr = 0.0005\n",
    "    m_c_arr, scaler = gd(data, numIter, lr)\n",
    "    return m_c_arr, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.07849910e-01 -4.87722360e-01 -1.26602310e+00 ...  1.57053288e-01\n",
      "  -7.14391060e-01  1.04172939e+00]\n",
      " [-4.07373680e-01 -4.87722360e-01  2.47056820e-01 ...  2.77147905e-01\n",
      "  -1.97799850e-03 -1.63100973e-03]\n",
      " [ 1.25178600e-01 -4.87722360e-01  1.01599907e+00 ... -3.72775908e-01\n",
      "  -6.01283666e-01 -3.02166006e-01]\n",
      " ...\n",
      " [-4.08311010e-01 -4.87722360e-01  2.47056820e-01 ...  2.77147905e-01\n",
      "   2.09493428e-01  1.66881277e-01]\n",
      " [-4.10619970e-01 -4.87722360e-01 -1.15221381e+00 ...  2.22987588e-01\n",
      "  -5.63643676e-02 -1.25883051e-01]\n",
      " [ 3.42908950e-01 -4.87722360e-01  1.01599907e+00 ...  2.41801440e+00\n",
      "   6.86796095e-01  1.07173881e+00]]\n",
      "(379, 20)\n",
      "[0.10723291 0.26273142 0.41945354 0.28557713 0.36537703 0.25767743\n",
      " 0.4212954  0.25916976 0.61094128 0.5664725  0.36898242 0.26125094\n",
      " 0.29737159 0.         0.12327836 0.19463896 0.18161627 0.14132659\n",
      " 0.18622902 0.15452442]\n",
      "0  Cost:  417.11580662461483\n",
      "1  Cost:  295.95793432289946\n",
      "2  Cost:  215.18952385410674\n",
      "3  Cost:  161.2382291394524\n",
      "4  Cost:  125.09846294951805\n",
      "5  Cost:  100.79361077045643\n",
      "6  Cost:  84.35649352832759\n",
      "7  Cost:  73.15326814577661\n",
      "8  Cost:  65.43497682972121\n",
      "9  Cost:  60.04003026558518\n",
      "10  Cost:  56.196785212974596\n",
      "11  Cost:  53.39251639842448\n",
      "12  Cost:  51.28643842225867\n",
      "13  Cost:  49.65195918903161\n",
      "14  Cost:  48.33833515047455\n",
      "15  Cost:  47.24520647271358\n",
      "16  Cost:  46.305684020949585\n",
      "17  Cost:  45.475115328680765\n",
      "18  Cost:  44.72362230960287\n",
      "19  Cost:  44.03114428933992\n",
      "20  Cost:  43.384145304646246\n",
      "21  Cost:  42.773427030840985\n",
      "22  Cost:  42.19267623354591\n",
      "23  Cost:  41.63750019442831\n",
      "24  Cost:  41.10478629741843\n",
      "25  Cost:  40.59227692887663\n",
      "26  Cost:  40.09828736751357\n",
      "27  Cost:  39.621518609174515\n",
      "28  Cost:  39.16093319983961\n",
      "29  Cost:  38.71567286866539\n",
      "30  Cost:  38.28500387613846\n",
      "31  Cost:  37.868280726129356\n",
      "32  Cost:  37.46492203606282\n",
      "33  Cost:  37.074394449120675\n",
      "34  Cost:  36.69620186034504\n",
      "35  Cost:  36.329878150048046\n",
      "36  Cost:  35.974982229504185\n",
      "37  Cost:  35.63109460950825\n",
      "38  Cost:  35.297814971180166\n",
      "39  Cost:  34.97476039635108\n",
      "40  Cost:  34.66156403252477\n",
      "41  Cost:  34.35787404508222\n",
      "42  Cost:  34.063352760570965\n",
      "43  Cost:  33.777675938557216\n",
      "44  Cost:  33.500532131554415\n",
      "45  Cost:  33.23162210693165\n",
      "46  Cost:  32.970658314053466\n",
      "47  Cost:  32.71736438594335\n",
      "48  Cost:  32.47147466863801\n",
      "49  Cost:  32.232733773864105\n",
      "50  Cost:  32.00089615221844\n",
      "51  Cost:  31.775725684993667\n",
      "52  Cost:  31.556995293376968\n",
      "53  Cost:  31.34448656409728\n",
      "54  Cost:  31.137989390798783\n",
      "55  Cost:  30.93730163052814\n",
      "56  Cost:  30.742228774784248\n",
      "57  Cost:  30.552583634605682\n",
      "58  Cost:  30.36818603918613\n",
      "59  Cost:  30.18886254751136\n",
      "60  Cost:  30.01444617251805\n",
      "61  Cost:  29.844776117274673\n",
      "62  Cost:  29.679697522693353\n",
      "63  Cost:  29.51906122628704\n",
      "64  Cost:  29.362723531496894\n",
      "65  Cost:  29.2105459871267\n",
      "66  Cost:  29.062395176433082\n",
      "67  Cost:  28.91814251543691\n",
      "68  Cost:  28.77766406003509\n",
      "69  Cost:  28.640840321508225\n",
      "70  Cost:  28.50755609003724\n",
      "71  Cost:  28.377700265856806\n",
      "72  Cost:  28.251165697691018\n",
      "73  Cost:  28.127849028132406\n",
      "74  Cost:  28.00765054564128\n",
      "75  Cost:  27.890474042857086\n",
      "76  Cost:  27.7762266809294\n",
      "77  Cost:  27.664818859589385\n",
      "78  Cost:  27.556164092696157\n",
      "79  Cost:  27.450178889007013\n",
      "80  Cost:  27.34678263793032\n",
      "81  Cost:  27.245897500034836\n",
      "82  Cost:  27.14744830209744\n",
      "83  Cost:  27.05136243648481\n",
      "84  Cost:  26.957569764672222\n",
      "85  Cost:  26.866002524714663\n",
      "86  Cost:  26.77659524249237\n",
      "87  Cost:  26.68928464656346\n",
      "88  Cost:  26.604009586463427\n",
      "89  Cost:  26.520710954299304\n",
      "90  Cost:  26.439331609494012\n",
      "91  Cost:  26.359816306542946\n",
      "92  Cost:  26.28211162565167\n",
      "93  Cost:  26.206165906129996\n",
      "94  Cost:  26.131929182423434\n",
      "95  Cost:  26.059353122668497\n",
      "96  Cost:  25.98839096966452\n",
      "97  Cost:  25.918997484158268\n",
      "98  Cost:  25.85112889034393\n",
      "99  Cost:  25.784742823484393\n",
      "100  Cost:  25.71979827956495\n",
      "101  Cost:  25.65625556689424\n",
      "102  Cost:  25.59407625957067\n",
      "103  Cost:  25.533223152737442\n",
      "104  Cost:  25.473660219551718\n",
      "105  Cost:  25.415352569797268\n",
      "106  Cost:  25.358266410072716\n",
      "107  Cost:  25.302369005491805\n",
      "108  Cost:  25.247628642832584\n",
      "109  Cost:  25.194014595077565\n",
      "110  Cost:  25.14149708728839\n",
      "111  Cost:  25.090047263760507\n",
      "112  Cost:  25.039637156406723\n",
      "113  Cost:  24.990239654320483\n",
      "114  Cost:  24.94182847447117\n",
      "115  Cost:  24.894378133486544\n",
      "116  Cost:  24.847863920479163\n",
      "117  Cost:  24.80226187087532\n",
      "118  Cost:  24.757548741206616\n",
      "119  Cost:  24.71370198482664\n",
      "120  Cost:  24.67069972851618\n",
      "121  Cost:  24.62852074994231\n",
      "122  Cost:  24.58714445593736\n",
      "123  Cost:  24.546550861567148\n",
      "124  Cost:  24.50672056995615\n",
      "125  Cost:  24.46763475284162\n",
      "126  Cost:  24.429275131827826\n",
      "127  Cost:  24.391623960313428\n",
      "128  Cost:  24.354664006066574\n",
      "129  Cost:  24.3183785344222\n",
      "130  Cost:  24.28275129207818\n",
      "131  Cost:  24.247766491467765\n",
      "132  Cost:  24.213408795685304\n",
      "133  Cost:  24.179663303945684\n",
      "134  Cost:  24.146515537555953\n",
      "135  Cost:  24.113951426380925\n",
      "136  Cost:  24.081957295782985\n",
      "137  Cost:  24.050519854019598\n",
      "138  Cost:  24.019626180079904\n",
      "139  Cost:  23.98926371194547\n",
      "140  Cost:  23.959420235258058\n",
      "141  Cost:  23.930083872380056\n",
      "142  Cost:  23.90124307183274\n",
      "143  Cost:  23.872886598098496\n",
      "144  Cost:  23.84500352177318\n",
      "145  Cost:  23.81758321005616\n",
      "146  Cost:  23.790615317565347\n",
      "147  Cost:  23.764089777465333\n",
      "148  Cost:  23.73799679289729\n",
      "149  Cost:  23.712326828699346\n",
      "[ -2.43038857  -0.67352591  -2.61367928   2.46968085  -2.55307517\n",
      "  11.04320147   0.142499    -4.88485515   2.38298429  -1.89236457\n",
      "  -4.91893743   2.30497691 -11.58807202  22.16133384   1.79975829\n",
      "  -1.3077454   -0.5233418   -1.11746489  -4.00732185  -2.94376022]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"gd_training_boston_x_y_train.csv\", delimiter = \",\")\n",
    "m_c_arr, scaler = run(data)\n",
    "print(m_c_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAns(testingData, m_c_arr):\n",
    "    y = np.arange(len(testingData)) * 0.0\n",
    "    #print(len(y_pred))\n",
    "    #constant = m_c_arr[-1]\n",
    "    #print(constant)\n",
    "    for i in range(len(testingData)):\n",
    "        y[i] = (testingData[i] * m_c_arr).sum()\n",
    "        #print((testingData[i] * m_c_arr).sum(), end = \" \")\n",
    "    print()    \n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 20)\n",
      "\n",
      "[12.45386399 28.99687949 21.54488262 23.88197011 20.4242129   4.74433931\n",
      " 28.78945627 24.41163029 18.87183171 22.51078526 24.74378082 18.72874649\n",
      " 20.19938989 21.34284693 36.92514944 23.15082054 23.77452403 27.06831289\n",
      " 19.22650335 30.94200367 22.99222011 22.97906281 30.04677231 34.70176943\n",
      " 33.83397254 15.50821019 22.2743091  31.28355458 23.39628626 32.52775254\n",
      " 18.17168149 24.6003752  22.90514048 25.70338991 15.21705456 28.27950247\n",
      " 25.57921771 20.17150846 24.3848363  10.3169657  10.34287836 28.02288897\n",
      " 28.90803773 18.60493898 19.65523495  6.68722189 39.23243946 25.31459327\n",
      " 33.05404291 16.86922729 17.73510818 41.01326997 17.35677998 20.06359087\n",
      " 17.24481082 21.8052962  18.78196424 22.37924357 15.19437241 17.33012916\n",
      " 15.60694402 28.02317431 24.60444172 25.72783097 17.23221463 15.39490529\n",
      " 32.52528641 16.73606029 24.67065762 21.3548831  29.00984803 24.52677417\n",
      " 19.91201936  9.29538205 36.91994502 25.52281269 27.96383258 25.70444171\n",
      " 16.04220447 33.80315709 19.3908381  22.19329147 22.34562135 10.7198171\n",
      " 17.38785173 31.50783124 28.28996224  8.89979532 19.01696883 19.17746236\n",
      " 20.82233754 20.43310677 20.53312893 13.10071583 20.10810808 24.89774996\n",
      " 41.81016344 17.28204648 33.32155935 25.87377378 27.04462364 22.87720812\n",
      " 24.37304092 30.48255566 16.28906714 25.2537465  21.03422218 38.82662095\n",
      " 22.90823232 16.63608061 27.91923152  3.78532753 14.61107749 16.81468718\n",
      " 36.99114465 20.44964138 22.02279055 24.68962345 21.17447803 21.57158834\n",
      " 15.39272447 34.43050983 21.07343263 23.35795139 19.59704505 20.11664157\n",
      " 18.21100625]\n"
     ]
    }
   ],
   "source": [
    "testingData = np.loadtxt(\"gd_test_boston_x_test.csv\", delimiter = \",\")\n",
    "df1 = pd.DataFrame(testingData)\n",
    "df1[13] = 1\n",
    "for i in range(14, 20):\n",
    "    df1[i] = df1[i-14] * df1[i-13]\n",
    "testingData = df1.values\n",
    "print(testingData.shape)\n",
    "testingData = scaler.transform(testingData)\n",
    "y_pred = getAns(testingData, m_c_arr)\n",
    "np.savetxt(\"GradientDescent.csv\", y_pred, fmt='%.5f',delimiter=\",\" )\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def stepGradient(m_c_arr, x, y, lr):\\n    m_c_slopeSum = m_c_arr * 0.0\\n    M = len(x)\\n    N = len(m_c_arr)\\n    for i in range(M):\\n        for j in range(N):\\n            smallAns += (m_c_arr[j] * x[i][j])\\n            #smallAns += (y[j] - m_c_arr[j] * x[i][j]) * x[i][j]\\n        smallAns = y[i] - smallAns\\n        smallAns = smallAns * (2/N) * \\n        m_c_slopeSum[i] = smallAns\\n    m_c_arr = m_c_arr - m_c_slopeSum * lr    '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def stepGradient(m_c_arr, x, y, lr):\n",
    "    m_c_slopeSum = m_c_arr * 0.0\n",
    "    M = len(x)\n",
    "    N = len(m_c_arr)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            smallAns += (m_c_arr[j] * x[i][j])\n",
    "            #smallAns += (y[j] - m_c_arr[j] * x[i][j]) * x[i][j]\n",
    "        smallAns = y[i] - smallAns\n",
    "        smallAns = smallAns * (2/N) * \n",
    "        m_c_slopeSum[i] = smallAns\n",
    "    m_c_arr = m_c_arr - m_c_slopeSum * lr    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def stepGradient(m_c_arr, x, y, lr):\n",
    "    m_c_slopeSum = m_c_arr * 0\n",
    "    numFeatures = len(m_c_arr)\n",
    "    numRows = len(x)\n",
    "    \n",
    "    for featureNo in range(numFeatures):\n",
    "        for i in range(numRows):\n",
    "            smallAns = (y[i] - (m_c_arr * x[i]).sum()) * x[i][featureNo]\n",
    "        m_c_slopeSum[featureNo] = smallAns * (-2/numRows)\n",
    "        \n",
    "    m_c_arr = m_c_arr - m_c_slopeSum * lr\n",
    "    return m_c_arr \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
